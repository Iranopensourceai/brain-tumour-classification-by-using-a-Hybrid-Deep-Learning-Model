{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## There are two methods that can be used to read data, which are mentioned in the following code for each method\n> * 1. Creating a data frame and saving the path and label of each image in the data frame\n> *   1.1 load images and labels in ram \n> *   1.2 Use flow_from_dataframe for read data\n> * 2. Use flow_from_Directory for read data:\n>   This method both reads the images and assigns its appropriate label to each image\n   ","metadata":{}},{"cell_type":"code","source":"'''\nCreating a data frame and saving the path and label of each image in the data frame\n'''\nimport os \nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm \nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nBATCH_SIZE=32\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nCHANNELS = 3\npath = '/kaggle/input/brain-tumor-classification-mri/'\nclass_label= [\"no_tumor\", \"pituitary_tumor\", \"meningioma_tumor\", \"glioma_tumor\"]\n\ndef generate_datafram(path):\n    train_labels = []\n    train_images = []\n\n    test_labels = []\n    test_images = []\n\n    for sub_dir,dir,files in os.walk(path):\n        for file in files:\n            img_path = os.path.join(sub_dir,file)\n            if img_path.split('/')[-3] == 'Training':\n                train_images.append(img_path)\n                train_labels.append(img_path.split('/')[-2])\n            elif img_path.split('/')[-3] == 'Testing':\n                test_images.append(img_path)\n                test_labels.append(img_path.split('/')[-2])\n    train_df = pd.DataFrame(list(zip(train_images,train_labels)),columns = ['images','labels'])\n    test_df = pd.DataFrame(list(zip(test_images,test_labels)),columns = ['images','labels'])\n    return train_df,test_df\n","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:19.902122Z","iopub.execute_input":"2023-01-20T13:28:19.903626Z","iopub.status.idle":"2023-01-20T13:28:19.916367Z","shell.execute_reply.started":"2023-01-20T13:28:19.903565Z","shell.execute_reply":"2023-01-20T13:28:19.915516Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"'''\n 1.1  load all images in ram\n'''\ndef preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    return img\ndef load_data_toram(train_df,test_df):\n    '''   save all images in one variable '''\n    N = train_df.shape[0]\n    x_train = np.empty((N, IMG_WIDTH, IMG_HEIGHT, CHANNELS), dtype=np.uint8)\n    for i, image_id in enumerate(tqdm(train_df['images'])): \n        x_train[i, :, :, :] = preprocess_image(\n            f'{image_id}'\n        )\n    N_t = test_df.shape[0]\n    x_test = np.empty((N_t, IMG_WIDTH, IMG_HEIGHT, CHANNELS), dtype=np.uint8)\n    for i, image_id in enumerate(tqdm(test_df['images'])):\n        x_test[i, :, :, :] = preprocess_image(\n            f'{image_id}'\n        )\n    '''   converting label to one-hot encoding '''\n    y_train = pd.get_dummies(train_df['labels']).values\n    y_test = pd.get_dummies(test_df['labels']).values\n    \n    return x_train,x_test,y_train,y_test","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:23.212398Z","iopub.execute_input":"2023-01-20T13:28:23.213665Z","iopub.status.idle":"2023-01-20T13:28:23.223265Z","shell.execute_reply.started":"2023-01-20T13:28:23.213623Z","shell.execute_reply":"2023-01-20T13:28:23.222162Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"'''\n 1.2 Use flow_from_dataframe for read data\n'''\n\ndef Read_flow_from_dataframe(train_df,test_df):\n    train_datagen= ImageDataGenerator()\n    train_set= train_datagen.flow_from_dataframe(train_df,\n                                               x_col='images',\n                                               y_col='labels',\n                                               target_size=(224, 224),\n                                               classes=class_label,\n                                               shuffle=True,\n                                               batch_size=BATCH_SIZE,\n                                               class_mode='categorical')\n\n    # test_datagen= ImageDataGenerator(rescale = 1./255)\n    test_datagen= ImageDataGenerator()\n\n    test_set= test_datagen.flow_from_dataframe(test_df,\n                                               x_col='images',\n                                               y_col='labels',\n                                               target_size=(224, 224),\n                                               classes=class_label,\n                                               shuffle=True,\n                                               batch_size=BATCH_SIZE,\n                                               class_mode='categorical')\n    return train_set,test_set","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:26.059619Z","iopub.execute_input":"2023-01-20T13:28:26.060033Z","iopub.status.idle":"2023-01-20T13:28:26.068538Z","shell.execute_reply.started":"2023-01-20T13:28:26.059996Z","shell.execute_reply":"2023-01-20T13:28:26.067535Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"'''\n 2 Use Read_flow_from_directory for read data\n'''\ndef Read_flow_from_directory(path):\n\n    train_generator = train_datagen.flow_from_directory(os.path.join(path,'Training'),\n                                                        batch_size = BATCH_SIZE, \n                                                        class_mode = 'categorical',\n                                                        classes=class_label,\n                                                        target_size = (224, 224))\n\n    test_generator = test_datagen.flow_from_directory( os.path.join(path,'Testing'),\n                                                       shuffle=False,\n                                                       batch_size = BATCH_SIZE,\n                                                       class_mode = 'categorical',\n                                                       classes=class_label,\n                                                       target_size = (224, 224))\n    return train_generator,test_generator","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:28.708861Z","iopub.execute_input":"2023-01-20T13:28:28.710211Z","iopub.status.idle":"2023-01-20T13:28:28.717311Z","shell.execute_reply.started":"2023-01-20T13:28:28.710161Z","shell.execute_reply":"2023-01-20T13:28:28.716414Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"'''\n  choose one method for read your data\n'''\n\ndef load_data(method):\n    \n    if method=='load_to_ram':\n        train_df,test_df=generate_datafram(path)\n        x_train,x_test,y_train,y_test = load_data_toram(train_df,test_df)\n        return x_train,x_test,y_train,y_test\n    if method=='Read_from_dataframe':\n        train_df,test_df=generate_datafram(path)\n        train_set,test_set = Read_flow_from_dataframe(train_df,test_df)\n        return train_set,test_set\n    if method=='Read_use_directory':\n        train_set,test_set = Read_flow_from_directory(path)\n        return train_set,test_set\n","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:31.181913Z","iopub.execute_input":"2023-01-20T13:28:31.182343Z","iopub.status.idle":"2023-01-20T13:28:31.189467Z","shell.execute_reply.started":"2023-01-20T13:28:31.182309Z","shell.execute_reply":"2023-01-20T13:28:31.188458Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def main():\n    method = 'Read_from_dataframe'\n    if method == 'load_to_ram':\n        x_train,x_test,y_train,y_test  = load_data('load_to_ram')\n    if method == 'Read_from_dataframe':\n        train_set,test_set  = load_data('Read_from_dataframe')\n    if method == 'Read_use_directory':\n        train_set,test_set  = load_data('Read_use_directory')\nmain()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:36:15.270008Z","iopub.execute_input":"2023-01-20T13:36:15.270865Z","iopub.status.idle":"2023-01-20T13:36:17.192742Z","shell.execute_reply.started":"2023-01-20T13:36:15.270815Z","shell.execute_reply":"2023-01-20T13:36:17.191857Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Found 2870 validated image filenames belonging to 4 classes.\nFound 394 validated image filenames belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git config --global user.name \"Siamand Avestan\"","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:48:34.306646Z","iopub.execute_input":"2023-01-20T13:48:34.307032Z","iopub.status.idle":"2023-01-20T13:48:35.421487Z","shell.execute_reply.started":"2023-01-20T13:48:34.307002Z","shell.execute_reply":"2023-01-20T13:48:35.419729Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"!git config --global user.email \"siamand.avestan@gmail.com\"","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:49:05.481762Z","iopub.execute_input":"2023-01-20T13:49:05.482288Z","iopub.status.idle":"2023-01-20T13:49:06.587188Z","shell.execute_reply.started":"2023-01-20T13:49:05.482249Z","shell.execute_reply":"2023-01-20T13:49:06.585661Z"},"trusted":true},"execution_count":85,"outputs":[]}]}